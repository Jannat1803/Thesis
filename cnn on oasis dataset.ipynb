{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image\nfrom imagehash import average_hash\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T06:17:05.502001Z","iopub.execute_input":"2024-03-17T06:17:05.502352Z","iopub.status.idle":"2024-03-17T06:17:05.533855Z","shell.execute_reply.started":"2024-03-17T06:17:05.502317Z","shell.execute_reply":"2024-03-17T06:17:05.532924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path1 = []\npath2 = []\npath3 = []\npath4 = []\nfor dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Non Demented'):\n    for filename in filenames:\n        path1.append(os.path.join(dirname, filename))\n        \nfor dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Mild Dementia'):\n    for filename in filenames:\n        path2.append(os.path.join(dirname, filename))\n        \nfor dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Moderate Dementia'):\n    for filename in filenames:\n        path3.append(os.path.join(dirname, filename))\n        \nfor dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Very mild Dementia'):\n    for filename in filenames:\n        path4.append(os.path.join(dirname, filename))  ","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:17:05.603930Z","iopub.execute_input":"2024-03-17T06:17:05.604238Z","iopub.status.idle":"2024-03-17T06:18:19.113318Z","shell.execute_reply.started":"2024-03-17T06:17:05.604195Z","shell.execute_reply":"2024-03-17T06:18:19.112283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Non Demented\")\nprint(\"No of images: \",len(path1))\ndef find_duplicates(image_paths):\n  seen_hashes = {}\n  duplicates = []\n  for path in image_paths:\n    try:\n      img = Image.open(path)\n      hash = average_hash(img)\n      if hash in seen_hashes:\n        duplicates.append((path, seen_hashes[hash]))\n      else:\n        seen_hashes[hash] = path\n    except (IOError, OSError) as e:\n      print(f\"Error processing {path}: {e}\")\n  return duplicates\n\n# Example usage:\nimage_paths = path1\nduplicates = find_duplicates(image_paths)\n\nif duplicates:\n  print(\"No of duplicate images: \", len(duplicates))\n#   print(\"Found duplicate images:\")\n#   for d in duplicates:\n#     print(f\"\\t{d[0]} is a duplicate of {d[1]}\")\nelse:\n  print(\"No duplicates found!\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:18:19.115124Z","iopub.execute_input":"2024-03-17T06:18:19.115418Z","iopub.status.idle":"2024-03-17T06:25:59.824544Z","shell.execute_reply.started":"2024-03-17T06:18:19.115393Z","shell.execute_reply":"2024-03-17T06:25:59.823620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Mild Dementia\")\nprint(\"No of images: \",len(path2))\ndef find_duplicates(image_paths):\n  seen_hashes = {}\n  duplicates = []\n  for path in image_paths:\n    try:\n      img = Image.open(path)\n      hash = average_hash(img)\n      if hash in seen_hashes:\n        duplicates.append((path, seen_hashes[hash]))\n      else:\n        seen_hashes[hash] = path\n    except (IOError, OSError) as e:\n      print(f\"Error processing {path}: {e}\")\n  return duplicates\n\n# Example usage:\nimage_paths = path2\nduplicates = find_duplicates(image_paths)\n\nif duplicates:\n  print(\"No of duplicate images: \", len(duplicates))\n#   print(\"Found duplicate images:\")\n#   for d in duplicates:\n#     print(f\"\\t{d[0]} is a duplicate of {d[1]}\")\nelse:\n  print(\"No duplicates found!\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:25:59.825781Z","iopub.execute_input":"2024-03-17T06:25:59.826064Z","iopub.status.idle":"2024-03-17T06:26:33.001605Z","shell.execute_reply.started":"2024-03-17T06:25:59.826039Z","shell.execute_reply":"2024-03-17T06:26:33.000708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Moderate Dementia\")\nprint(\"No of images: \",len(path3))\ndef find_duplicates(image_paths):\n  seen_hashes = {}\n  duplicates = []\n  for path in image_paths:\n    try:\n      img = Image.open(path)\n      hash = average_hash(img)\n      if hash in seen_hashes:\n        duplicates.append((path, seen_hashes[hash]))\n      else:\n        seen_hashes[hash] = path\n    except (IOError, OSError) as e:\n      print(f\"Error processing {path}: {e}\")\n  return duplicates\n\n# Example usage:\nimage_paths = path3\nduplicates = find_duplicates(image_paths)\n\nif duplicates:\n  print(\"No of duplicate images: \", len(duplicates))\n#   print(\"Found duplicate images:\")\n#   for d in duplicates:\n#     print(f\"\\t{d[0]} is a duplicate of {d[1]}\")\nelse:\n  print(\"No duplicates found!\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:26:33.004069Z","iopub.execute_input":"2024-03-17T06:26:33.004341Z","iopub.status.idle":"2024-03-17T06:26:36.164680Z","shell.execute_reply.started":"2024-03-17T06:26:33.004313Z","shell.execute_reply":"2024-03-17T06:26:36.163602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Very mild Dementia\")\nprint(\"No of images: \",len(path4))\ndef find_duplicates(image_paths):\n  seen_hashes = {}\n  duplicates = []\n  for path in image_paths:\n    try:\n      img = Image.open(path)\n      hash = average_hash(img)\n      if hash in seen_hashes:\n        duplicates.append((path, seen_hashes[hash]))\n      else:\n        seen_hashes[hash] = path\n    except (IOError, OSError) as e:\n      print(f\"Error processing {path}: {e}\")\n  return duplicates\n\n# Example usage:\nimage_paths = path4\nduplicates = find_duplicates(image_paths)\n\nif duplicates:\n  print(\"No of duplicate images: \", len(duplicates))\n#   print(\"Found duplicate images:\")\n#   for d in duplicates:\n#     print(f\"\\t{d[0]} is a duplicate of {d[1]}\")\nelse:\n  print(\"No duplicates found!\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:26:36.165823Z","iopub.execute_input":"2024-03-17T06:26:36.166114Z","iopub.status.idle":"2024-03-17T06:28:12.547615Z","shell.execute_reply.started":"2024-03-17T06:26:36.166090Z","shell.execute_reply":"2024-03-17T06:28:12.546759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Weights on Duplicates**","metadata":{}},{"cell_type":"code","source":"# def remove_duplicates_and_create_folder(image_paths, output_folder=\"non_demented_unique_images\", hash_size=8):\n#   seen_hashes = {}\n#   unique_paths = []\n\n#   if not os.path.exists(output_folder):\n#     os.makedirs(output_folder)  # Create the output folder if it doesn't exist\n\n#   for path in image_paths:\n#     try:\n#       img = Image.open(path)\n#       hash = average_hash(img, hash_size=hash_size)\n#       if hash not in seen_hashes:\n#         seen_hashes[hash] = path\n#         unique_paths.append(path)  # Add unique path to the list\n#         os.rename(path, os.path.join(output_folder, os.path.basename(path)))  # Move unique image to output folder\n#       elif path in image_paths:  # Ensure path is still in the list to avoid errors\n#         image_paths.remove(path)  # Remove duplicate path from the list to avoid processing again\n#         # print(f\"Removed duplicate: {path}\")\n#     except (IOError, OSError) as e:\n#       print(f\"Error processing {path}: {e}\")\n\n#   print(\"Duplicate removal completed!\")\n#   print(f\"Number of unique images in '{output_folder}': {len(unique_paths)}\")\n\n# # Example usage:\n# image_paths = path1\n# remove_duplicates_and_create_folder(image_paths)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:28:12.548854Z","iopub.execute_input":"2024-03-17T06:28:12.549132Z","iopub.status.idle":"2024-03-17T06:28:12.553884Z","shell.execute_reply.started":"2024-03-17T06:28:12.549107Z","shell.execute_reply":"2024-03-17T06:28:12.553059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport os\nfrom distutils.dir_util import copy_tree, remove_tree\n\nfrom PIL import Image\nfrom random import randint\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow import keras\nfrom keras import Sequential, Input\nfrom keras.layers import Dense, Dropout\nfrom keras.layers import Conv2D, Flatten\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:28:12.554902Z","iopub.execute_input":"2024-03-17T06:28:12.555163Z","iopub.status.idle":"2024-03-17T06:28:33.484502Z","shell.execute_reply.started":"2024-03-17T06:28:12.555140Z","shell.execute_reply":"2024-03-17T06:28:33.483678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing packages \n\nimport numpy as np\nimport pandas as pd\nimport keras\nimport matplotlib.pyplot as plt\nimport re\nimport os\nimport random\nimport tensorflow as tf\nimport plotly.express as px\nfrom keras.applications.mobilenet_v2 import MobileNetV2\nfrom keras.models import Sequential\nfrom PIL import Image\nfrom keras.layers import Conv2D,Flatten,Dense,Dropout,BatchNormalization,MaxPooling2D\nfrom sklearn.preprocessing import OneHotEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import auc, average_precision_score, confusion_matrix, roc_auc_score, f1_score, confusion_matrix, precision_recall_fscore_support\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetV2B1\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import clone_model\nfrom matplotlib.colors import LogNorm, LinearSegmentedColormap\nfrom PIL import Image\nfrom scipy.stats import skew\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:28:33.485698Z","iopub.execute_input":"2024-03-17T06:28:33.486209Z","iopub.status.idle":"2024-03-17T06:28:34.222002Z","shell.execute_reply.started":"2024-03-17T06:28:33.486183Z","shell.execute_reply":"2024-03-17T06:28:34.221069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE=(224,224)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:28:34.223161Z","iopub.execute_input":"2024-03-17T06:28:34.223448Z","iopub.status.idle":"2024-03-17T06:28:34.227487Z","shell.execute_reply.started":"2024-03-17T06:28:34.223423Z","shell.execute_reply":"2024-03-17T06:28:34.226631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_samples=5002\n# Undersample large classes\nvery_mild_demented= random.sample(path4, k=target_samples)\nnon_demented= random.sample(path1, k=target_samples)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:28:34.231078Z","iopub.execute_input":"2024-03-17T06:28:34.231352Z","iopub.status.idle":"2024-03-17T06:28:34.249486Z","shell.execute_reply.started":"2024-03-17T06:28:34.231325Z","shell.execute_reply":"2024-03-17T06:28:34.248815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder()\nencoder.fit([[0],[1],[2],[3]])","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:28:34.250543Z","iopub.execute_input":"2024-03-17T06:28:34.250891Z","iopub.status.idle":"2024-03-17T06:28:34.274225Z","shell.execute_reply.started":"2024-03-17T06:28:34.250858Z","shell.execute_reply":"2024-03-17T06:28:34.273437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nfrom collections import defaultdict\n\ndef load_and_resize_image(path):\n    img = Image.open(path)\n    img = img.resize((224, 224))\n    img = np.array(img)\n    return img\n\n# Empty objects to store the data and the class labels (result) in\ndata = []\nlabels = []\n\n# Dictionary to keep track of image paths and their occurrence counts\nimage_counts = defaultdict(int)\n\n# Loop through each category and transform data and result into right format (128x128x3 & one-hot encoded)\n# and merge categories together\nfor path in non_demented:\n    img = load_and_resize_image(path)\n    if img.shape == (224, 224, 3):\n        # Check for duplicate images\n        if image_counts[path] == 0:\n            # If image is not a duplicate, append it to data and labels\n            data.append(img)\n            labels.append(encoder.transform([[0]]).toarray())\n        else:\n            # Assign lower weight to duplicate images\n            data.append(img)\n            labels.append(encoder.transform([[0]]).toarray()* 0.1)  # You can adjust the weight as per your requirement\n        image_counts[path] += 1\n\nfor path in very_mild_demented:\n    img = load_and_resize_image(path)\n    if img.shape == (224, 224, 3):\n        # Check for duplicate images\n        if image_counts[path] == 0:\n            # If image is not a duplicate, append it to data and labels\n            data.append(img)\n            labels.append(encoder.transform([[1]]).toarray())\n        else:\n            # Assign lower weight to duplicate images\n            data.append(img)\n            labels.append(encoder.transform([[1]]).toarray() * 0.1)  # You can adjust the weight as per your requirement\n        image_counts[path] += 1\n        \nfor path in path2:\n    img = load_and_resize_image(path)\n    if img.shape == (224, 224, 3):\n        # Check for duplicate images\n        if image_counts[path] == 0:\n            # If image is not a duplicate, append it to data and labels\n            data.append(img)\n            labels.append(encoder.transform([[2]]).toarray())\n        else:\n            # Assign lower weight to duplicate images\n            data.append(img)\n            labels.append(encoder.transform([[2]]).toarray() * 0.1)  # You can adjust the weight as per your requirement\n        image_counts[path] += 1\n        \nfor path in path3:\n    img = load_and_resize_image(path)\n    if img.shape == (224, 224, 3):\n        # Check for duplicate images\n        if image_counts[path] == 0:\n            # If image is not a duplicate, append it to data and labels\n            data.append(img)\n            labels.append(encoder.transform([[3]]).toarray())\n        else:\n            # Assign lower weight to duplicate images\n            data.append(img)\n            labels.append(encoder.transform([[3]]).toarray() * 0.1)  # You can adjust the weight as per your requirement\n        image_counts[path] += 1","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:28:34.275303Z","iopub.execute_input":"2024-03-17T06:28:34.275561Z","iopub.status.idle":"2024-03-17T06:29:43.239142Z","shell.execute_reply.started":"2024-03-17T06:28:34.275540Z","shell.execute_reply":"2024-03-17T06:29:43.238103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Empty objects to store the data and the class labels (result) in\n# data = []\n# labels = []\n# # Loop through each category and transform data and result into right format (128x128x3 & one-hot encoded) \n# # and merge categories together\n# for path in non_demented:\n#     img = Image.open(path)\n#     img = img.resize((128,128))\n#     img = np.array(img)\n#     #print(img.shape)\n#     if(img.shape == (128,128,3)):\n#         data.append(img)\n#         labels.append(encoder.transform([[0]]).toarray())\n\n# for path in very_mild_demented:\n#     img = Image.open(path)\n#     img = img.resize((128,128))\n#     img = np.array(img)\n#     if(img.shape == (128,128,3)):\n#         data.append(img)\n#         labels.append(encoder.transform([[1]]).toarray())\n        \n# for path in path2:\n#     img = Image.open(path)\n#     img = img.resize((128,128))\n#     img = np.array(img)\n#     if(img.shape == (128,128,3)):\n#         data.append(img)\n#         labels.append(encoder.transform([[2]]).toarray()) \n        \n# for path in path3:\n#     img = Image.open(path)\n#     img = img.resize((128,128))\n#     img = np.array(img)\n#     if(img.shape == (128,128,3)):\n#         data.append(img)\n#         labels.append(encoder.transform([[3]]).toarray())\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:43.240502Z","iopub.execute_input":"2024-03-17T06:29:43.240904Z","iopub.status.idle":"2024-03-17T06:29:43.245865Z","shell.execute_reply.started":"2024-03-17T06:29:43.240868Z","shell.execute_reply":"2024-03-17T06:29:43.245028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=np.array(data)\nlabels=np.array(labels)\n#class_images.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:43.247184Z","iopub.execute_input":"2024-03-17T06:29:43.247433Z","iopub.status.idle":"2024-03-17T06:29:43.982699Z","shell.execute_reply.started":"2024-03-17T06:29:43.247412Z","shell.execute_reply":"2024-03-17T06:29:43.981716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:43.983921Z","iopub.execute_input":"2024-03-17T06:29:43.984182Z","iopub.status.idle":"2024-03-17T06:29:43.989862Z","shell.execute_reply.started":"2024-03-17T06:29:43.984161Z","shell.execute_reply":"2024-03-17T06:29:43.989030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = np.array(labels)\nlabels = labels.reshape((15494,4))\nlabels.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:43.990959Z","iopub.execute_input":"2024-03-17T06:29:43.991239Z","iopub.status.idle":"2024-03-17T06:29:44.002519Z","shell.execute_reply.started":"2024-03-17T06:29:43.991216Z","shell.execute_reply":"2024-03-17T06:29:44.001760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# # Function to check for duplicate images (choose one method):\n# def is_duplicate(img1, img2, hash_size=8):  # Using image hashing\n#     hash1 = average_hash(img1, hash_size=hash_size)  # Assume average_hash function is defined\n#     hash2 = average_hash(img2, hash_size=hash_size)\n#     return hash1 == hash2\n\n# # Calculate class weights based on duplicate counts\n# class_weights = {}\n# seen_images = set()\n# for img, label in zip(data, labels):\n#     if img not in seen_images:\n#         class_weights[np.argmax(label)] = class_weights.get(np.argmax(label), 0) + 1\n#         seen_images.add(img)\n#     else:\n#         if is_duplicate(img, next(item for item in seen_images if item == img)):  # Find original duplicate\n#             class_weights[np.argmax(label)] += 0.2  # Adjust duplicate weight as needed\n\n# # Normalize class weights to sum to 1\n# total_weight = sum(class_weights.values())\n# for label, weight in class_weights.items():\n#     class_weights[label] = weight / total_weight\n\n# # Create ImageDataGenerator with class weights\n# datagen = ImageDataGenerator(rescale=1./255)  # Adjust for your preprocessing needs\n\n# # Use the class weights during training\n# # model.fit(np.array(data), np.array(labels), class_weight=class_weights, ...)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:44.003507Z","iopub.execute_input":"2024-03-17T06:29:44.003846Z","iopub.status.idle":"2024-03-17T06:29:44.013567Z","shell.execute_reply.started":"2024-03-17T06:29:44.003807Z","shell.execute_reply":"2024-03-17T06:29:44.012723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sm = SMOTE(random_state=42)\ntrain_data, train_labels = sm.fit_resample(data.reshape(-1, IMG_SIZE[0] * IMG_SIZE[1] * 3), labels)\ntrain_data = train_data.reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)\n\nprint(train_data.shape, train_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:44.014889Z","iopub.execute_input":"2024-03-17T06:29:44.015319Z","iopub.status.idle":"2024-03-17T06:29:50.126971Z","shell.execute_reply.started":"2024-03-17T06:29:44.015245Z","shell.execute_reply":"2024-03-17T06:29:50.125995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting the data into train, test,\n\n#train_data, test_data, train_labels, test_labels = train_test_split(test_data, train_labels, test_size = 0.2, random_state=42)\ntraining_set, test_data, training_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:50.127980Z","iopub.execute_input":"2024-03-17T06:29:50.128282Z","iopub.status.idle":"2024-03-17T06:29:50.941659Z","shell.execute_reply.started":"2024-03-17T06:29:50.128257Z","shell.execute_reply":"2024-03-17T06:29:50.940808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(training_set.shape)\nprint(training_labels.shape)\nprint(test_data.shape)\nprint(test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:50.942767Z","iopub.execute_input":"2024-03-17T06:29:50.943043Z","iopub.status.idle":"2024-03-17T06:29:50.948577Z","shell.execute_reply.started":"2024-03-17T06:29:50.943021Z","shell.execute_reply":"2024-03-17T06:29:50.947752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow import keras\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# # Assuming you have functions to:\n# # - load_images(paths): Loads images from a list of paths\n# # - is_duplicate(image1, image2): Checks if two images are duplicates\n\n# def create_weighted_datagenerator(image_paths, labels, batch_size, duplicate_weight=0.5):\n#   \"\"\"\n#   Creates an ImageDataGenerator that assigns weights based on duplicates.\n\n#   Args:\n#       image_paths: List of image paths.\n#       labels: List of corresponding labels for each image.\n#       batch_size: Batch size for the data generator.\n#       duplicate_weight: Weight to be assigned to duplicate images (0-1).\n\n#   Returns:\n#       An ImageDataGenerator with class weights.\n#   \"\"\"\n#   class_weights = {}\n#   seen_images = set()\n#   for path, label in zip(image_paths, labels):\n#     if path not in seen_images:\n#       class_weights[label] = class_weights.get(label, 0) + 1\n#       seen_images.add(path)\n#     else:\n#       class_weights[label] += duplicate_weight\n\n#   # Normalize class weights to sum to 1\n#   total_weight = sum(class_weights.values())\n#   for label, weight in class_weights.items():\n#     class_weights[label] = weight / total_weight\n\n#   datagen = ImageDataGenerator(rescale=1./255)  # Adjust for your preprocessing needs\n#   datagen.fit(load_images(image_paths))  # Fit the data generator on all images\n\n#   return datagen.flow(load_images(image_paths), labels, batch_size=batch_size, class_weight=class_weights)\n\n# image_paths = training_set\n# labels = training_labels","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:50.949946Z","iopub.execute_input":"2024-03-17T06:29:50.950225Z","iopub.status.idle":"2024-03-17T06:29:50.963731Z","shell.execute_reply.started":"2024-03-17T06:29:50.950201Z","shell.execute_reply":"2024-03-17T06:29:50.962887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Create an ImageDataGenerator instance for augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=10,      # Rotate images randomly by up to 10 degrees\n    width_shift_range=0.1,  # Shift images horizontally by up to 10% of the width\n    height_shift_range=0.1, # Shift images vertically by up to 10% of the height\n    horizontal_flip=True,   # Flip images horizontally\n    zoom_range=0.1          # Zoom in/out on images by 10%\n)\n\n# Fit the ImageDataGenerator to your training data\ndatagen.fit(training_set)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:50.964826Z","iopub.execute_input":"2024-03-17T06:29:50.965078Z","iopub.status.idle":"2024-03-17T06:30:02.251839Z","shell.execute_reply.started":"2024-03-17T06:29:50.965056Z","shell.execute_reply":"2024-03-17T06:30:02.251007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train_data, val_data, new_train_labels, val_labels = train_test_split(\n    training_set, training_labels, test_size=0.2, random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:30:02.252982Z","iopub.execute_input":"2024-03-17T06:30:02.253258Z","iopub.status.idle":"2024-03-17T06:30:02.897985Z","shell.execute_reply.started":"2024-03-17T06:30:02.253235Z","shell.execute_reply":"2024-03-17T06:30:02.896999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(new_train_data.shape)\nprint(new_train_labels.shape)\nprint(val_data.shape)\nprint(val_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:30:02.899448Z","iopub.execute_input":"2024-03-17T06:30:02.900134Z","iopub.status.idle":"2024-03-17T06:30:02.905394Z","shell.execute_reply.started":"2024-03-17T06:30:02.900096Z","shell.execute_reply":"2024-03-17T06:30:02.904546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Conv2D,Flatten,Dense,Dropout,BatchNormalization,MaxPooling2D\nmodel = Sequential()\n\nmodel.add(Conv2D(32,kernel_size =(2,2),input_shape = (224, 224,3),padding = 'Same'))\nmodel.add(Conv2D(32,kernel_size =(2,2),activation='relu',padding = 'Same'))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64,kernel_size =(2,2),activation='relu',padding = 'Same'))\nmodel.add(Conv2D(64,kernel_size =(2,2),activation='relu',padding = 'Same'))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2),strides = (2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\n          \nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:30:02.906659Z","iopub.execute_input":"2024-03-17T06:30:02.907265Z","iopub.status.idle":"2024-03-17T06:30:04.066136Z","shell.execute_reply.started":"2024-03-17T06:30:02.907235Z","shell.execute_reply":"2024-03-17T06:30:04.065346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc')\n]","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:30:04.067258Z","iopub.execute_input":"2024-03-17T06:30:04.067546Z","iopub.status.idle":"2024-03-17T06:30:04.089013Z","shell.execute_reply.started":"2024-03-17T06:30:04.067522Z","shell.execute_reply":"2024-03-17T06:30:04.088177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy',optimizer = 'Adamax',metrics=METRICS)\n          \nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:30:04.090057Z","iopub.execute_input":"2024-03-17T06:30:04.090285Z","iopub.status.idle":"2024-03-17T06:30:04.127311Z","shell.execute_reply.started":"2024-03-17T06:30:04.090265Z","shell.execute_reply":"2024-03-17T06:30:04.126490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the training data to the model and validate it using the validation data\n#history = model.fit(x_train,y_train,epochs=50,batch_size=32,verbose=1,validation_data=(x_test,y_test))\nhistory = model.fit(new_train_data, new_train_labels, validation_data=(val_data, val_labels), epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:30:04.131557Z","iopub.execute_input":"2024-03-17T06:30:04.132310Z","iopub.status.idle":"2024-03-17T07:08:58.542057Z","shell.execute_reply.started":"2024-03-17T06:30:04.132284Z","shell.execute_reply":"2024-03-17T07:08:58.540980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert true test labels to integers\ny_test_int = np.argmax(test_labels, axis=1)\n\n# Evaluate on test set \ntesteval = model.evaluate(test_data, test_labels, verbose=2)\n\n# Print performance metrics (loss and accuracy)\nprint(\"Test Loss:\", testeval[0])\nprint(\"Test Accuracy:\", testeval[1])","metadata":{"execution":{"iopub.status.busy":"2024-03-17T07:08:58.543609Z","iopub.execute_input":"2024-03-17T07:08:58.543993Z","iopub.status.idle":"2024-03-17T07:09:02.675452Z","shell.execute_reply.started":"2024-03-17T07:08:58.543965Z","shell.execute_reply":"2024-03-17T07:09:02.674358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"accuracy\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-17T07:09:02.676903Z","iopub.execute_input":"2024-03-17T07:09:02.677272Z","iopub.status.idle":"2024-03-17T07:09:03.871112Z","shell.execute_reply.started":"2024-03-17T07:09:02.677239Z","shell.execute_reply":"2024-03-17T07:09:03.870148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting the test data\n\npred_labels =model.predict(test_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T07:09:03.872310Z","iopub.execute_input":"2024-03-17T07:09:03.872603Z","iopub.status.idle":"2024-03-17T07:09:08.759607Z","shell.execute_reply.started":"2024-03-17T07:09:03.872578Z","shell.execute_reply":"2024-03-17T07:09:08.758679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASSES = [ 'Non_Demented',\n            'Mild_Dementia',\n            'Moderate_Dementia',\n            'Very_Mild_Dementia']","metadata":{"execution":{"iopub.status.busy":"2024-03-17T07:09:08.761214Z","iopub.execute_input":"2024-03-17T07:09:08.761492Z","iopub.status.idle":"2024-03-17T07:09:08.765846Z","shell.execute_reply.started":"2024-03-17T07:09:08.761470Z","shell.execute_reply":"2024-03-17T07:09:08.764896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T07:09:08.767148Z","iopub.execute_input":"2024-03-17T07:09:08.767489Z","iopub.status.idle":"2024-03-17T07:09:08.971426Z","shell.execute_reply.started":"2024-03-17T07:09:08.767459Z","shell.execute_reply":"2024-03-17T07:09:08.970530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\n# Assuming test_labels are integer labels\none_hot_test_labels = tf.keras.utils.to_categorical(y_test_int , num_classes=4)\n\n# Get the predicted class labels from the one-hot encoded format\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(one_hot_test_labels, axis=1)\n\n# Compute the confusion matrix\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\n# Plot the confusion matrix as a heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T07:09:08.972672Z","iopub.execute_input":"2024-03-17T07:09:08.973360Z","iopub.status.idle":"2024-03-17T07:09:09.347143Z","shell.execute_reply.started":"2024-03-17T07:09:08.973323Z","shell.execute_reply":"2024-03-17T07:09:09.346184Z"},"trusted":true},"execution_count":null,"outputs":[]}]}